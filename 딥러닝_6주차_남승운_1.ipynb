{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d230c2f2-afd5-4536-a505-92d21814eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x=None\n",
    "        self.y=None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        out=x*y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx=dout*self.y # x와 y를 바꾼다\n",
    "        dy=dout*self.x\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd4b53f7-48d0-47ce-8b50-40fd048175d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax=1.1\n",
    "\n",
    "#계층\n",
    "mul_apple_layer=MulLayer()\n",
    "mul_tax_layer=MulLayer()\n",
    "\n",
    "#순전파\n",
    "apple_price=mul_apple_layer.forward(apple, apple_num)\n",
    "price=mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46a9b7ce-34fc-42b2-83db-975a82239f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2 110.00000000000001 200\n"
     ]
    }
   ],
   "source": [
    "#역전파\n",
    "dprice=1\n",
    "dapple_price, dtax=mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num=mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(dapple, dapple_num, dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "995e56ca-f45a-4cbb-b529-c101070a8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out=x+y\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx=dout*1\n",
    "        dy=dout*1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74a56059-ceda-4ef2-836e-8255057575fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "110.00000000000001 2.2 3.3000000000000003 165.0 650\n"
     ]
    }
   ],
   "source": [
    "apple=100\n",
    "apple_num=2\n",
    "orange=150\n",
    "orange_num=3\n",
    "tax=1.1\n",
    "\n",
    "mul_apple_layer=MulLayer()\n",
    "mul_orange_layer=MulLayer()\n",
    "add_apple_orange_layer=AddLayer()\n",
    "mul_tax_layer=MulLayer()\n",
    "\n",
    "apple_price=mul_apple_layer.forward(apple, apple_num)\n",
    "orange_price=mul_orange_layer.forward(orange, orange_num)\n",
    "all_price=add_apple_orange_layer.forward(apple_price, orange_price)\n",
    "price=mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "dprice=1\n",
    "dall_price, dtax=mul_tax_layer.backward(dprice)\n",
    "dapple_price, dorange_price=add_apple_orange_layer.backward(dall_price)\n",
    "dorange, dorange_num=mul_orange_layer.backward(dorange_price)\n",
    "dapple, dapple_num=mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(price)\n",
    "print(dapple_num, dapple, dorange, dorange_num, dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7266a4ed-188f-475c-a660-4f63e90cc468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask=None\n",
    "\n",
    "    def forawrd(self, x):\n",
    "        self.mask=(x<=0)\n",
    "        out=x.copy()\n",
    "        out[self.mask]=0\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask]=0\n",
    "        dx=dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee3266dc-e938-47d4-9886-a1085a635215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x=np.array([[1.0, -0.5],[-2.0,3.0]])\n",
    "print(x)\n",
    "\n",
    "mask=(x<=0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90e6091f-a16e-42a5-8ab2-ec88412973ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out=None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out=1/(1+np.exp(-x))\n",
    "        self.out=out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx=dout*(1.0-self.out)*self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cac55daa-dacd-4587-b043-15e05543d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.rand(2)\n",
    "w=np.random.rand(2, 3)\n",
    "B=np.random.rand(3)\n",
    "\n",
    "x.shape\n",
    "w.shape\n",
    "B.shape\n",
    "Y=np.dot(x,w)+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e88391cd-cf5e-400b-a026-5548f79cb30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0]\n",
      " [10 10 10]]\n",
      "[[ 1  2  3]\n",
      " [11 12 13]]\n"
     ]
    }
   ],
   "source": [
    "X_dot_W=np.array([[0,0,0],[10,10,10]])\n",
    "B=np.array([1,2,3])\n",
    "\n",
    "print(X_dot_W)\n",
    "print(X_dot_W+B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2701d921-3a8a-4653-b53a-532504006683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dY=np.array([[1,2,3],[4,5,6]])\n",
    "dY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17bcb039-7738-4263-8f20-7477f2fc3285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dB=np.sum(dY, axis=0)\n",
    "dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d6ce3a0-d61d-4342-bc78-5a6db0ca3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W=W\n",
    "        self.b=b\n",
    "        self.x=None\n",
    "        self.dW=None\n",
    "        self.db=None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x=x\n",
    "        out=np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx=np.dot(dout, self.W.T)\n",
    "        self.dW=np.dot(self.x.T, dout)\n",
    "        self.db=np.sum(dout, axis=0)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e75b63c1-7806-40d0-8a13-3d3d8796db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞선 장의 함수 재구현\n",
    "def softmax(a):\n",
    "    c=np.max(a)\n",
    "    exp_a=np.exp(a-c)\n",
    "    sum_exp_a=np.sum(exp_a)\n",
    "    y=exp_a/sum_exp_a\n",
    "    return y\n",
    "    \n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t=t.reshape(1, t.size)\n",
    "        y=y.reshape(1, y.size)\n",
    "\n",
    "    batch_size=y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2ae1f6d-479d-4902-9a29-c4ca54652f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss=None\n",
    "        self.y=None\n",
    "        self.t=None\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t=t\n",
    "        self.y=softmax(x)\n",
    "        self.loss=cross_enrtopy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size=self.t.shape[0]\n",
    "        dx=(self.y-self.t)/batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c6a1e8a-cdaa-4aab-a30a-e5e8529e23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params={}\n",
    "        self.params['W1']=weight_init_std*np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1']=np.zeros(hidden_size)\n",
    "        self.params['W2']=weight_init_std*np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2']=np.zeros(output_size)\n",
    "\n",
    "        self.layers=OrderedDict()\n",
    "        self.layers['Affine1']=Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1']=Relu()\n",
    "        self.layers['Affine2']=Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer=SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x=layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y=self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y=self.predict(x)\n",
    "        y=np.argmax(y, axis=1)\n",
    "        if t.ndim!=1 : t=np.argmax(t, axis=1)\n",
    "\n",
    "        accuracy=np.sum(y==t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W=lambda W: self.loss(x, t)\n",
    "\n",
    "        grads={}\n",
    "        grads['W1']=numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1']=numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2']=numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2']=numerical_gradient(loss_W, self.params['b2'])\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        self.loss(x, t)\n",
    "        dout=1\n",
    "        dout=self.lastLayer.backward(dout)\n",
    "        layers=list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout=layer.backward(dout)\n",
    "\n",
    "        grads={}\n",
    "        grads['W1']=self.Layers['Affine1'].dW\n",
    "        grads['b1']=self.Layers['Affine1'].db\n",
    "        grads['W2']=self.Layers['Affine2'].dW\n",
    "        grads['b2']=self.Layers['Affine2'].db\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ceb2e86d-de82-4e78-a2ce-5c5274daae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:2.457481698930841e-13\n",
      "b1:1.003254276529808e-12\n",
      "W2:8.553409856342778e-13\n",
      "b2:1.194600016130032e-10\n"
     ]
    }
   ],
   "source": [
    "#기울기 확인\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "network=TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "x_batch=x_train[:3]\n",
    "t_batch=t_train[:3]\n",
    "grad_numerical=network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop=network.gradient(x_batch, t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff=np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(key + \":\" + str(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "394e1e1e-fbaa-4476-88ed-c51d61ecd312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15465 0.1518\n",
      "0.9008333333333334 0.903\n",
      "0.92195 0.9245\n",
      "0.9300333333333334 0.9294\n",
      "0.9424833333333333 0.9412\n",
      "0.9506333333333333 0.9475\n",
      "0.9564 0.9539\n",
      "0.9616 0.9576\n",
      "0.9651666666666666 0.9619\n",
      "0.9686833333333333 0.9648\n",
      "0.971 0.9667\n",
      "0.9727666666666667 0.9656\n",
      "0.97465 0.9694\n",
      "0.9750333333333333 0.9682\n",
      "0.97445 0.9673\n",
      "0.9785333333333334 0.9714\n",
      "0.9798 0.9717\n",
      "0.9811666666666666 0.9716\n",
      "0.982 0.9726\n",
      "0.98025 0.9723\n",
      "0.983 0.9736\n",
      "0.9837666666666667 0.973\n",
      "0.98375 0.9722\n",
      "0.9846666666666667 0.9729\n",
      "0.9860666666666666 0.974\n",
      "0.9863166666666666 0.975\n",
      "0.9873 0.9761\n",
      "0.9873833333333333 0.9737\n",
      "0.9878666666666667 0.9749\n",
      "0.9884833333333334 0.9743\n",
      "0.9889833333333333 0.9747\n",
      "0.9886 0.9746\n",
      "0.9888833333333333 0.9743\n",
      "0.9904833333333334 0.9745\n",
      "0.9904333333333334 0.974\n",
      "0.99085 0.9745\n",
      "0.9905166666666667 0.974\n",
      "0.9918333333333333 0.9752\n",
      "0.9923333333333333 0.975\n",
      "0.9929833333333333 0.9752\n",
      "0.9927666666666667 0.9751\n",
      "0.9929166666666667 0.975\n",
      "0.9933833333333333 0.974\n",
      "0.9933333333333333 0.9748\n",
      "0.9939333333333333 0.9751\n",
      "0.9944 0.9736\n",
      "0.9937333333333334 0.9748\n",
      "0.9946 0.9747\n",
      "0.9947833333333334 0.974\n",
      "0.9948833333333333 0.9744\n",
      "0.9950333333333333 0.9744\n",
      "0.9953333333333333 0.9744\n",
      "0.9956 0.9745\n",
      "0.9961 0.9745\n",
      "0.9961333333333333 0.9755\n",
      "0.99635 0.9748\n",
      "0.9965 0.9747\n",
      "0.9964 0.9741\n",
      "0.9966166666666667 0.9751\n",
      "0.9960166666666667 0.975\n",
      "0.9967666666666667 0.9739\n",
      "0.9970333333333333 0.9752\n",
      "0.9974 0.9748\n",
      "0.9974333333333333 0.974\n",
      "0.9972666666666666 0.9749\n",
      "0.99785 0.9753\n",
      "0.9978 0.9749\n",
      "0.9978333333333333 0.9747\n",
      "0.9982166666666666 0.9748\n",
      "0.9979333333333333 0.9748\n",
      "0.9981166666666667 0.9746\n",
      "0.9982333333333333 0.9753\n",
      "0.99825 0.974\n",
      "0.9985833333333334 0.9747\n",
      "0.9985333333333334 0.9744\n",
      "0.9987166666666667 0.9748\n",
      "0.9988166666666667 0.9745\n",
      "0.9988333333333334 0.9746\n",
      "0.9988 0.9742\n",
      "0.9986833333333334 0.9739\n",
      "0.9990833333333333 0.9747\n",
      "0.9990833333333333 0.9743\n",
      "0.9989333333333333 0.9747\n",
      "0.99925 0.9751\n",
      "0.9992166666666666 0.9738\n",
      "0.99915 0.9741\n",
      "0.99925 0.9747\n",
      "0.9992166666666666 0.9743\n",
      "0.99945 0.9742\n",
      "0.9992166666666666 0.9741\n",
      "0.9993666666666666 0.9744\n",
      "0.9994166666666666 0.9742\n",
      "0.9995833333333334 0.9745\n",
      "0.9995666666666667 0.9743\n",
      "0.9996166666666667 0.9738\n",
      "0.9995166666666667 0.9738\n",
      "0.9995666666666667 0.9749\n",
      "0.9995833333333334 0.9742\n",
      "0.9996833333333334 0.9744\n",
      "0.9996833333333334 0.974\n",
      "0.9997166666666667 0.9741\n",
      "0.9997 0.9745\n",
      "0.9997333333333334 0.974\n",
      "0.9996666666666667 0.9738\n",
      "0.9997166666666667 0.9739\n",
      "0.9997666666666667 0.9743\n",
      "0.9997833333333334 0.9747\n",
      "0.9998 0.9752\n",
      "0.9998 0.9736\n",
      "0.9998333333333334 0.9739\n",
      "0.99985 0.9734\n",
      "0.99985 0.9744\n",
      "0.9998333333333334 0.974\n",
      "0.9998833333333333 0.9737\n",
      "0.9999 0.9743\n",
      "0.99985 0.9748\n",
      "0.9999 0.974\n",
      "0.9999166666666667 0.9746\n",
      "0.9999166666666667 0.9744\n",
      "0.9999 0.9743\n",
      "0.9999 0.9745\n",
      "0.9998833333333333 0.9739\n",
      "0.9998833333333333 0.9738\n",
      "0.9999166666666667 0.9735\n",
      "0.9999333333333333 0.9742\n",
      "0.9999 0.974\n",
      "0.9999166666666667 0.9746\n",
      "0.9998333333333334 0.975\n",
      "0.99995 0.9746\n",
      "0.9999333333333333 0.9741\n",
      "0.9999333333333333 0.9735\n",
      "0.99995 0.9736\n",
      "0.9999833333333333 0.9744\n",
      "0.9999666666666667 0.9741\n",
      "0.9999166666666667 0.9744\n",
      "0.9999833333333333 0.9741\n",
      "0.99995 0.9748\n",
      "0.9999833333333333 0.9743\n",
      "0.9999833333333333 0.9742\n",
      "0.9999666666666667 0.974\n",
      "1.0 0.9739\n",
      "0.9999333333333333 0.9739\n",
      "0.9999666666666667 0.9744\n",
      "0.9999833333333333 0.9745\n",
      "0.99995 0.9739\n",
      "0.9999666666666667 0.9741\n",
      "0.99995 0.9739\n",
      "0.9999833333333333 0.9744\n",
      "1.0 0.974\n",
      "0.9999833333333333 0.9746\n",
      "1.0 0.9736\n",
      "0.9999833333333333 0.9738\n",
      "0.9999666666666667 0.9743\n",
      "0.9999833333333333 0.9738\n",
      "0.9999833333333333 0.9737\n",
      "0.9999666666666667 0.9745\n",
      "0.9999833333333333 0.9742\n",
      "0.9999833333333333 0.9739\n",
      "1.0 0.9736\n",
      "0.9999833333333333 0.9739\n",
      "0.9999833333333333 0.9739\n",
      "0.9999833333333333 0.9739\n",
      "0.9999666666666667 0.9741\n",
      "0.9999833333333333 0.9735\n",
      "1.0 0.9745\n",
      "1.0 0.9737\n",
      "0.9999833333333333 0.9741\n"
     ]
    }
   ],
   "source": [
    "iters_num = 100000\n",
    "train_size=x_train.shape[0]\n",
    "batch_size=100\n",
    "learning_rate=0.1\n",
    "\n",
    "train_loss_list=[]\n",
    "train_acc_list=[]\n",
    "test_acc_list=[]\n",
    "\n",
    "iter_per_epoch=max(train_size/batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask=np.random.choice(train_size, batch_size)\n",
    "    x_batch=x_train[batch_mask]\n",
    "    t_batch=t_train[batch_mask]\n",
    "\n",
    "    grad=network.gradient(x_batch, t_batch)\n",
    "\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key]-=learning_rate*grad[key]\n",
    "\n",
    "    loss=network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i%iter_per_epoch==0:\n",
    "        train_acc=network.accuracy(x_train, t_train)\n",
    "        test_acc=network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108f193-3005-413d-a49a-c2771f62176f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
